{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting: ATL\n",
      "--- Table 1 ---\n",
      "Selecting: AUS\n",
      "--- Table 1 ---\n",
      "Selecting: bos\n",
      "--- Table 1 ---\n",
      "Selecting: ORD\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n",
      "Selecting: CLE\n",
      "--- Table 1 ---\n",
      "Selecting: DFW\n",
      "--- Table 1 ---\n",
      "Selecting: DEN\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n",
      "Selecting: FLL\n",
      "--- Table 1 ---\n",
      "Selecting: GUM\n",
      "--- Table 1 ---\n",
      "Selecting: HKG\n",
      "--- Table 1 ---\n",
      "Selecting: HNL\n",
      "--- Table 1 ---\n",
      "Selecting: IAH\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n",
      "--- Table 3 ---\n",
      "Selecting: LAS\n",
      "--- Table 1 ---\n",
      "Selecting: LAX\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n",
      "Selecting: LHR\n",
      "--- Table 1 ---\n",
      "Selecting: MEX\n",
      "--- Table 1 ---\n",
      "Selecting: MSP\n",
      "--- Table 1 ---\n",
      "Selecting: MSY\n",
      "--- Table 1 ---\n",
      "Selecting: EWR\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n",
      "Selecting: LGA\n",
      "--- Table 1 ---\n",
      "Selecting: SNA\n",
      "--- Table 1 ---\n",
      "Selecting: MCO\n",
      "--- Table 1 ---\n",
      "Selecting: PDX\n",
      "--- Table 1 ---\n",
      "Selecting: PHL\n",
      "--- Table 1 ---\n",
      "Selecting: PHX\n",
      "--- Table 1 ---\n",
      "Selecting: RDU\n",
      "--- Table 1 ---\n",
      "Selecting: SAT\n",
      "--- Table 1 ---\n",
      "Selecting: SAN\n",
      "--- Table 1 ---\n",
      "Selecting: SFO\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n",
      "Selecting: SEA\n",
      "--- Table 1 ---\n",
      "Selecting: NRT\n",
      "--- Table 1 ---\n",
      "Selecting: DCA\n",
      "--- Table 1 ---\n",
      "Selecting: IAD\n",
      "--- Table 1 ---\n",
      "--- Table 2 ---\n"
     ]
    }
   ],
   "source": [
    "# Scrape lounge data from United website\n",
    "url = 'https://www.united.com/en/us/fly/travel/airport/united-club-and-lounge-locations.html'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "dropdown = Select(wait.until(EC.presence_of_element_located((By.ID, \"lookup-airport-united-lounges\"))))\n",
    "rows_all = []\n",
    "\n",
    "for option in dropdown.options[1:]:\n",
    "    value = option.get_attribute('value')\n",
    "    print('Selecting:', value.upper())\n",
    "\n",
    "    dropdown.select_by_value(value)\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    tables = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//table\")))\n",
    "    for i, table in enumerate(tables):\n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        for row in rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            rows_all.append([value.upper(), i+1]+[col.text for col in cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine lounge data into df\n",
    "cols = ['airport', 'type', 'location', 'hours', 'amenities']\n",
    "\n",
    "df = pd.DataFrame(rows_all, columns=cols)\n",
    "df = df[df['amenities'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean lounge hours\n",
    "df['hours'] = df['hours'].str.split('\\n')\n",
    "df = df.explode('hours')\n",
    "\n",
    "df['days'] = df['hours'].str.replace(r\"\\d|:|-|–|a\\.m\\.|p\\.m\\.|p\\.m\", \"\", regex=True)\n",
    "df_days = df['days'].str.strip().str.lower().str.replace(', ', '|').str.replace(' and ', '|', regex=True).str.replace('\\s+', '_', regex=True).str.get_dummies(sep='|')\n",
    "df_days.loc[df_days['daily']==1, ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']] = 1\n",
    "df_days.loc[df_days['sun_fri']==1, ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'sunday']] = 1\n",
    "\n",
    "df_hours = df['hours'].str.replace(r\"\\.\", \"\", regex=True).str.findall(r\"\\d|:|-|–|am|pm\").str.join('').str.split('[-–]', expand=True)[[0, 1]]\n",
    "df_hours.columns = ['open', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amenities = df['amenities'].str.replace('\\n', '|').str.replace('[\\s+-]', '_', regex=True).str.lower().str.get_dummies(sep='|')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
